{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metapub import PubMedFetcher\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pybliometrics.scopus import ScopusSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# PubMed Analysis\n",
    "\n",
    "---\n",
    "\n",
    "- User inputs the keyowrd of interest, starting year to fetch articles,\n",
    "  and ending year\n",
    "\n",
    "- Bellow code cell saves the results to a pandas dataframe, and if\n",
    "  inputted by user, saves the results to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jukit_cell_id": "NONE"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Keyword to search for articles in the DataBase:  Plasmonic\n",
      "Starting year:  2018\n",
      "Ending year:  2018\n",
      "Save file to a csv? (file_path/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-1:  212\n",
      "2018-2:  299\n",
      "2018-3:  123\n",
      "2018-4:  124\n",
      "2018-5:  110\n",
      "2018-6:  131\n",
      "2018-7:  758\n",
      "2018-8:  216\n",
      "2018-9:  167\n",
      "2018-10:  4422\n",
      "2018-11:  1990\n",
      "2018-12:  936\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-1</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-2</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-3</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-4</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-5</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-6</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-7</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-8</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-9</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-10</td>\n",
       "      <td>4422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-11</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-12</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  articles\n",
       "0    2018-1       212\n",
       "1    2018-2       299\n",
       "2    2018-3       123\n",
       "3    2018-4       124\n",
       "4    2018-5       110\n",
       "5    2018-6       131\n",
       "6    2018-7       758\n",
       "7    2018-8       216\n",
       "8    2018-9       167\n",
       "9   2018-10      4422\n",
       "10  2018-11      1990\n",
       "11  2018-12       936"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = str(input('Keyword to search for articles in the DataBase: '))\n",
    "year_1 = int(input('Starting year: '))\n",
    "year_2 = int(input('Ending year: '))\n",
    "save_path = str(input('Save file to a csv? (file_path/n): '))\n",
    "\n",
    "# Fetching the PubMed database\n",
    "fetch = PubMedFetcher()\n",
    "\n",
    "# Creating empty pandas dataframe with 'date' and 'articles' columns\n",
    "pubmed_df = pd.DataFrame({'date': [],\n",
    "                          'articles': []})\n",
    "\n",
    "# Creating a list containing the number correspondant to every year month\n",
    "month_list = np.arange(1, 13, 1)\n",
    "\n",
    "# Creating a pandas dataframe with every month number in one column, named\n",
    "# 'month', and in the other column 'ends', the corresponding months ending\n",
    "# day\n",
    "months_days = pd.DataFrame({'month': month_list,\n",
    "                            'ends': [31, 28, 31, 30, 31, 30, 31, 31, 30, 31,\n",
    "                                    30, 31]})\n",
    "\n",
    "# Creating a list for with every year in the given range\n",
    "year_list = np.arange(year_1, year_2 + 1, 1)\n",
    "\n",
    "# Looping for every month in every year\n",
    "for year in year_list:\n",
    "    for month in months_days['month']:\n",
    "        # Creating a variable to store the current loop month ending day\n",
    "        endsin = (months_days.loc[months_days['month'] == month, 'ends'])[month-1]\n",
    "\n",
    "        # Fetching all articles containing the given keyword, in the date\n",
    "        # ranging from the first day (1) of the current loop month, to the\n",
    "        # above defined current loop month last day\n",
    "        pmids = fetch.pmids_for_query(f'{keyword} '+str(year)+f'/{month}/01[MDAT] : '+str(year)+f'/{month}/{endsin}[MDAT]',retmax=100000000)\n",
    "\n",
    "        # Appending to the result dataframe, in the first available row\n",
    "        # (given by the dataframe length), the current loop date in the\n",
    "        # format year-month, and the number of published articles in this\n",
    "        # month, given by the above articles fetch length\n",
    "        pubmed_df.loc[len(pubmed_df)] = [f'{year}-{month}', len(pmids)]\n",
    "\n",
    "        # Printing for tracking the current loop date, in the year-month\n",
    "        # format, and the number of articles containing the given keyword\n",
    "        # found in the Scoupus database with corresponding year-month\n",
    "        # publication date\n",
    "        print(f\"{year}-{month}: \", len(pmids))\n",
    "\n",
    "        # Sleeping for avoiding to many/simultaneous API requests, if any\n",
    "        # error is presented during this function execution, this sleeping\n",
    "        # time may be enlarged\n",
    "        sleep(0.1)\n",
    "\n",
    "# Converting the result dataframe 'date' column to pandas date format\n",
    "pd.to_datetime(pubmed_df.date, format=\"%Y-%m\")\n",
    "\n",
    "# If optional argument save_path is given, the bellow saving loop is\n",
    "# executed\n",
    "if save_path != 'n' and save_path != 'N':\n",
    "    pathcsv = f'{save_path}/{keyword}_pubmed.csv'\n",
    "    pubmed_df.to_csv(path_or_buf=pathcsv)\n",
    "pubmed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Read PubMed saved csv file\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jukit_cell_id": "NONE"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Path to the csv file:  /home/eduardotc/Programação/my_gits/materials_chempy/example_data/Upconversion_pubmed.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  articles\n",
      "0  2015-01-01        17\n",
      "1  2015-02-01        20\n",
      "2  2015-03-01        33\n",
      "3  2015-04-01        22\n",
      "4  2015-05-01        20\n",
      "5  2015-06-01        17\n",
      "6  2015-07-01        20\n",
      "7  2015-08-01        31\n",
      "8  2015-09-01        20\n",
      "9  2015-10-01        12\n",
      "10 2015-11-01        64\n",
      "11 2015-12-01        17\n"
     ]
    }
   ],
   "source": [
    "# Reading the csv file with pandas, stating that the file first column\n",
    "# corresponds to the index values (row number)\n",
    "csv_path = str(input('Path to the csv file: '))\n",
    "df_readed = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "# Converting 'date' column to pandas date format\n",
    "df_readed['date'] = pd.to_datetime(df_readed.date, format=\"%Y-%m\")\n",
    "\n",
    "print(df_readed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "NONE"
   },
   "outputs": [],
   "source": [
    "csv_path = str(input('Path to the csv file: '))\n",
    "# Reading in a pandas dataframe the csv\n",
    "csv_stat = read_pubmed_csv(csv_path)\n",
    "\n",
    "# Getting the date column sum, mean and max\n",
    "csv_stat = csv_stat.groupby(csv_stat['date'].dt.year)['articles'].agg(['sum', 'mean', 'max'])\n",
    "\n",
    "return csv_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "NONE"
   },
   "outputs": [],
   "source": [
    "def scopusfetcher(keyword, year_1, year_2, **kwargs):\n",
    "    \"\"\"\n",
    "\n",
    "    Queryes from the Scopus database the number of articles containing a\n",
    "    specific keyword, in an specified year range, returning a pandas dataframe\n",
    "    with one column named 'date' containing the year month in format year-month\n",
    "    and one column named 'articles', with the number of published articles\n",
    "    containing the given keyword in that corresponding month.If the argument\n",
    "    csv_path is given, the function saves the results to a csv file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    keyword : str\n",
    "        Keyword to search articles tha contains it.\n",
    "        Required.\n",
    "\n",
    "    year_1 : int\n",
    "        Starting year to search for articles. Remember that pubmed was created\n",
    "        in january 1996.\n",
    "        Required.\n",
    "\n",
    "    year_2 : int\n",
    "        Ending year to search for articles.\n",
    "        Required.\n",
    "\n",
    "    save_path : str\n",
    "        Path to save the dataframe into a csv file.\n",
    "        Optional.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scopus_df : pandas.DataFrame\n",
    "        Pandas dataframe with every selected year months in a column named\n",
    "        \"date\", and the corresponding number of published articles in that\n",
    "        month containing the given keyword in other column named \"articles\".\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Querying, per month, the number of published articles containing the\n",
    "    keyword 'Upconversion', in the year of 2015, in the Scopus database.\n",
    "\n",
    "    >>> scopus_df = scopusfetcher('Upconversion', 2015, 2015, save_path=\"./tmp\")\n",
    "    2015-january:  136\n",
    "    2015-february:  126\n",
    "    2015-march:  122\n",
    "    2015-april:  135\n",
    "    2015-june:  154\n",
    "    2015-july:  178\n",
    "    2015-august:  187\n",
    "    2015-september:  149\n",
    "    2015-october:  125\n",
    "    2015-november:  120\n",
    "    2015-december:  120\n",
    "    >>> print(scopus_df)\n",
    "             date  articles\n",
    "    0  2015-01-01       136\n",
    "    1  2015-02-01       126\n",
    "    2  2015-03-01       122\n",
    "    3  2015-04-01       135\n",
    "    4  2015-06-01       154\n",
    "    5  2015-07-01       178\n",
    "    6  2015-08-01       187\n",
    "    7  2015-09-01       149\n",
    "    8  2015-10-01       125\n",
    "    9  2015-11-01       120\n",
    "    10 2015-12-01       120\n",
    "\n",
    "    \"\"\"\n",
    "    # Defining optional argument save_path\n",
    "    save_path = kwargs.get('save_path', None)\n",
    "\n",
    "    # Creating a list with every month in the year\n",
    "    months_list = ['january', 'february', 'march', 'april', 'june', 'july',\n",
    "                   'august', 'september', 'october', 'november', 'december']\n",
    "\n",
    "    # Creating an empty dataframe with one column named 'date' and one column\n",
    "    # named 'articles'\n",
    "    scopus_df = pd.DataFrame({'date': [],\n",
    "                       'articles': []})\n",
    "\n",
    "    # Creating a list containing every year in the given range\n",
    "    years_list = np.arange(year_1, year_2+1, 1)\n",
    "\n",
    "    # Looping for every month in every year\n",
    "    for year in years_list:\n",
    "        for month in months_list:\n",
    "            # Searching articles containing the given keyword, in the specific\n",
    "            # month and year, in the scopus database. subscriber=False refers\n",
    "            # to be using a free API key.\n",
    "            s = ScopusSearch(f'KEY {keyword}, PUBDATETXT({month} {year})',\n",
    "                             subscriber=False)\n",
    "\n",
    "            # Prints the year-month and number of published articles (size of\n",
    "            # the search result)\n",
    "            print(f\"{year}-{month}: \", s.get_results_size())\n",
    "\n",
    "            # Appending to previously created empty list, always in the first\n",
    "            # available row (given by the length of the list), the date in the\n",
    "            # format year-month of current loop, and the number of published\n",
    "            # articles containing the keyword in this month\n",
    "            scopus_df.loc[len(scopus_df)] = [f'{year}-{month}',\n",
    "                                             s.get_results_size()]\n",
    "\n",
    "            # Some errors have being ocurring while querying the database, to\n",
    "            # try to minimize it, i setted a relatvielly large sleep time, may\n",
    "            # be lowered to test your specific case results.\n",
    "            sleep(2)\n",
    "\n",
    "    # Converting the 'date' column to pandas datetime format\n",
    "    scopus_df['date'] = pd.to_datetime(scopus_df.date.astype(str),\n",
    "                                       format=\"%Y-%B\")\n",
    "\n",
    "    # If optional argument save_path is given, the saving loop bellow is\n",
    "    # executed\n",
    "    if save_path:\n",
    "        pathcsv = f'{save_path}/{keyword}_scopus.csv'\n",
    "        scopus_df.to_csv(path_or_buf=pathcsv)\n",
    "\n",
    "    return scopus_df\n",
    "\n",
    "\n",
    "def df_statistics(df):\n",
    "    \"\"\"\n",
    "\n",
    "    Given a dataframe with 'date' column, in the format year-month, returns\n",
    "    the sum, the mean and the max of the 'date' column, organized as well in\n",
    "    a dataframe.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    df : pd.DataFrame\n",
    "        Pandas DataFrame, with one column named 'date', in the year-month\n",
    "        format, and one column with integer values correlating to the date\n",
    "        column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_stat : pd.DataFrame\n",
    "        Pandas dataframe with the results, one column named 'sum', one named\n",
    "        'mean' and one named 'max', all the columns refers to the values\n",
    "        calculated from the original dataframe 'date' column values.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Defining an example dataframe, formated similar to articles databases\n",
    "    functions present in this file.\n",
    "\n",
    "    >>> x = ['2015-01-01', '2015-02-01', '2015-03-01', '2015-04-01',\n",
    "    ...      '2015-06-01', '2015-07-01', '2015-08-01', '2015-09-01',\n",
    "    ...      '2015-10-01', '2015-11-01', '2015-12-01']\n",
    "    >>> y = [136, 126, 122, 135, 154, 178, 187, 149, 125, 120, 120]\n",
    "    >>> df_test = pd.DataFrame({'date': x,\n",
    "    ...                         'articles': y})\n",
    "    >>> stat_test_df = df_statistics(df_test)\n",
    "    >>> print(stat_test_df)\n",
    "           sum        mean  max\n",
    "    Date ...\n",
    "    2015  1552  141.090909  187\n",
    "    \"\"\"\n",
    "    df_clean = clean_df(df)\n",
    "    # df_clean['Date'] = pd.to_datetime(df.date.astype(str), format=\"%Y-%m-%B\")\n",
    "    df_stat = df_clean.groupby(df_clean['Date'].dt.year)['Articles'].agg(['sum', 'mean', 'max'])\n",
    "    return df_stat\n",
    "\n",
    "\n",
    "def find_matching_positions(string1, string2):\n",
    "    \"\"\"\n",
    "\n",
    "    Find the matching letters between 2 strings, and attribute the positions\n",
    "    values of the matching cases to a list variable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string1 : str\n",
    "        First string to check matching letters\n",
    "\n",
    "    string2 : str\n",
    "        Second string to compare matching letters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matching_postions : list\n",
    "        List with the positions of matching letters between the 2 strings\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Find the matching letters between the strings 'hello' and 'hallo'\n",
    "\n",
    "    >>> string1 = \"hello\"\n",
    "    >>> string2 = \"hallo\"\n",
    "    >>> positions = find_matching_positions(string1, string2)\n",
    "    >>> print(\"Matching positions:\", positions)\n",
    "    Matching positions: [0, 2, 3, 4]\n",
    "\n",
    "    Find the matching letters between '2015-02-01' and '2015-01-01'\n",
    "\n",
    "    >>> string1 = \"2015-02-01\"\n",
    "    >>> string2 = \"2015-01-01\"\n",
    "    >>> positions = find_matching_positions(string1, string2)\n",
    "    >>> print(\"Matching positions:\", positions)\n",
    "    Matching positions: [0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
    "    \"\"\"\n",
    "    matching_positions = []\n",
    "\n",
    "    # Make sure both strings are of the same length\n",
    "    if len(string1) != len(string2):\n",
    "        raise ValueError(\"Both strings must have the same length\")\n",
    "\n",
    "    for i in range(len(string1)):\n",
    "        if string1[i] == string2[i]:\n",
    "            matching_positions.append(i)\n",
    "\n",
    "    return matching_positions\n",
    "\n",
    "\n",
    "def clean_csv(csv_path):\n",
    "    \"\"\"\n",
    "\n",
    "    Reads a csv file, organizing its columns, returning a dataframe with one\n",
    "    'Date' column (pandas datetime), one 'Year' column (pandas datetime), one\n",
    "    'Month' column (pandas datetime), and if the csv has an articles column,\n",
    "    the cleaned dataframe also has a 'Articles' column (integer).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Path to the csv file to be cleaned\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_clean : Pandas.DataFrame\n",
    "        Pandas dataframe of cleaned and organized csv\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Clean example_data csv\n",
    "\n",
    "    >>> test_clean_csv = clean_csv('../example_data/Upconversion_pubmed.csv')\n",
    "    >>> print(test_clean_csv)\n",
    "        Year  Month       Date  Articles\n",
    "    0   2015      1 2015-01-01        17\n",
    "    1   2015      2 2015-02-01        20\n",
    "    2   2015      3 2015-03-01        33\n",
    "    3   2015      4 2015-04-01        22\n",
    "    4   2015      5 2015-05-01        20\n",
    "    5   2015      6 2015-06-01        17\n",
    "    6   2015      7 2015-07-01        20\n",
    "    7   2015      8 2015-08-01        31\n",
    "    8   2015      9 2015-09-01        20\n",
    "    9   2015      1 2015-01-01        12\n",
    "    10  2015     11 2015-11-01        64\n",
    "    11  2015     12 2015-12-01        17\n",
    "\n",
    "    \"\"\"\n",
    "    month_new = []\n",
    "    df = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "    # Creating empty dataframe in case readed csv 'date' column is shorter\n",
    "    # than 7\n",
    "    if (len(df.date[0])) < 7:\n",
    "        df_split = pd.DataFrame({'a': [],\n",
    "                                'b': []})\n",
    "\n",
    "    # Creating empty dataframe in case readed csv 'date' column is longer\n",
    "    # than 7\n",
    "    else:\n",
    "        df_split = pd.DataFrame({'a': [],\n",
    "                                'b': [],\n",
    "                                'c': []})\n",
    "\n",
    "    df_clean = pd.DataFrame({'Year': [],\n",
    "                        'Month': [],\n",
    "                        'Date': [],\n",
    "                        'Articles': []})\n",
    "\n",
    "    # Iterating for every column from inputted dataframe\n",
    "    for col in df.columns:\n",
    "\n",
    "        # If input dataframe has a column named 'articles'\n",
    "        if col == 'articles' or col == 'Articles':\n",
    "            df_clean['Articles'] = df['articles']\n",
    "\n",
    "        # If input dataframe has a column named 'date'\n",
    "        if col == 'date' or col == 'Date':\n",
    "\n",
    "            # Iterating for every value from the row 'date'\n",
    "            for values in df.date:\n",
    "\n",
    "                # Adding each date element to empty dataframe\n",
    "                df_split.loc[len(df_split)] = values.split(\"-\")\n",
    "\n",
    "            # Iterating for every column in the new created every\n",
    "            # date element df\n",
    "            for cols in df_split.columns:\n",
    "\n",
    "                # If length from every element from the first row >\n",
    "                # 4 (correspond (High chances of being a year column)\n",
    "                if len(df_split[cols][0]) == 4:\n",
    "                    df_clean['Year'] = df_split[cols]\n",
    "\n",
    "                # Getting total column values range (max - min)\n",
    "                col_min = int(df_split[cols].min())\n",
    "                col_max = int(df_split[cols].max())\n",
    "                col_diff = col_max - col_min\n",
    "\n",
    "                # Loop if the column range is between 17 and 4 (high chances of\n",
    "                # being a month column\n",
    "                if 17 > col_diff > 4:\n",
    "                    df_clean['Month'] = df_split[cols]\n",
    "\n",
    "    # Removing month column trailing zeroes\n",
    "    for number in df_clean.Month:\n",
    "        month_new.append(int(str(number).rstrip('0')))\n",
    "\n",
    "    # Converting year month and date columns to pandas datetime\n",
    "    df_clean['Year'] = pd.to_datetime(df_clean['Year'])\n",
    "    df_clean['Year'] = df_clean.Year.dt.year\n",
    "    df_clean['Month'] = month_new\n",
    "    df_clean['Month'] = pd.to_datetime(df_clean['Month'], format=\"%m\")\n",
    "    df_clean['Month'] = df_clean.Month.dt.month\n",
    "    df_clean['Date'] =  pd.to_datetime(df_clean[['Year', 'Month']].assign(Day=1))\n",
    "\n",
    "\n",
    "    return(df_clean)\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    \"\"\"\n",
    "\n",
    "    Organize and clean a pandas DataFrame, returning a dataframe with one\n",
    "    'Date' column (pandas datetime), one 'Year' column (pandas datetime), one\n",
    "    'Month' column (pandas datetime), and if the csv has an articles column,\n",
    "    the cleaned dataframe also has a 'Articles' column (integer).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Pandas Dataframe to be cleaned\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_clean : pandas.DataFrame\n",
    "        Cleaned and organized pandas DataFrame\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Clean a fetched pubmed dataframe with the keyword 'Singlet Oxygen' in the\n",
    "    year of 2017\n",
    "\n",
    "    >>> test_df = pubmedfetcher('Singlet Oxygen', 2017, 2017)\n",
    "    2017-1:  10\n",
    "    2017-2:  20\n",
    "    2017-3:  29\n",
    "    2017-4:  8\n",
    "    2017-5:  9\n",
    "    2017-6:  8\n",
    "    2017-7:  2\n",
    "    2017-8:  11\n",
    "    2017-9:  11\n",
    "    2017-10:  16\n",
    "    2017-11:  128\n",
    "    2017-12:  27\n",
    "    >>> test_clean = clean_df(test_df)\n",
    "    >>> print(test_clean)\n",
    "        Year  Month       Date  Articles\n",
    "    0   2017      1 2017-01-01        10\n",
    "    1   2017      2 2017-02-01        20\n",
    "    2   2017      3 2017-03-01        29\n",
    "    3   2017      4 2017-04-01         8\n",
    "    4   2017      5 2017-05-01         9\n",
    "    5   2017      6 2017-06-01         8\n",
    "    6   2017      7 2017-07-01         2\n",
    "    7   2017      8 2017-08-01        11\n",
    "    8   2017      9 2017-09-01        11\n",
    "    9   2017      1 2017-01-01        16\n",
    "    10  2017     11 2017-11-01       128\n",
    "    11  2017     12 2017-12-01        27\n",
    "\n",
    "    \"\"\"\n",
    "    month_new = []\n",
    "\n",
    "    # Creating empty dataframe in case readed csv 'date' column is shorter\n",
    "    # than 7\n",
    "    if (len(df.date[0])) < 7:\n",
    "        df_split = pd.DataFrame({'a': [],\n",
    "                                'b': []})\n",
    "\n",
    "    # Creating empty dataframe in case readed csv 'date' column is longer\n",
    "    # than 7\n",
    "    else:\n",
    "        df_split = pd.DataFrame({'a': [],\n",
    "                                'b': [],\n",
    "                                'c': []})\n",
    "\n",
    "    df_clean = pd.DataFrame({'Year': [],\n",
    "                        'Month': [],\n",
    "                        'Date': [],\n",
    "                        'Articles': []})\n",
    "\n",
    "    # Iterating for every column from inputted dataframe\n",
    "    for col in df.columns:\n",
    "\n",
    "        # If input dataframe has a column named 'articles'\n",
    "        if col == 'articles' or col == 'Articles':\n",
    "            df_clean['Articles'] = df['articles']\n",
    "\n",
    "        # If input dataframe has a column named 'date'\n",
    "        if col == 'date' or col == 'Date':\n",
    "\n",
    "            # Iterating for every value from the row 'date'\n",
    "            for values in df.date:\n",
    "\n",
    "                # Adding each date element to empty dataframe\n",
    "                df_split.loc[len(df_split)] = values.split(\"-\")\n",
    "\n",
    "            # Iterating for every column in the new created every\n",
    "            # date element df\n",
    "            for cols in df_split.columns:\n",
    "\n",
    "                # If length from every element from the first row >\n",
    "                # 4 (correspond (High chances of being a year column)\n",
    "                if len(df_split[cols][0]) == 4:\n",
    "                    df_clean['Year'] = df_split[cols]\n",
    "\n",
    "                # Getting total column values range (max - min)\n",
    "                col_min = int(df_split[cols].min())\n",
    "                col_max = int(df_split[cols].max())\n",
    "                col_diff = col_max - col_min\n",
    "\n",
    "                # Loop if the column range is between 17 and 4 (high chances of\n",
    "                # being a month column\n",
    "                if 17 > col_diff > 4:\n",
    "                    df_clean['Month'] = df_split[cols]\n",
    "\n",
    "    # Removing month column trailing zeroes\n",
    "    for number in df_clean.Month:\n",
    "        month_new.append(int(str(number).rstrip('0')))\n",
    "\n",
    "    # Converting year month and date columns to pandas datetime\n",
    "    df_clean['Year'] = pd.to_datetime(df_clean['Year'])\n",
    "    df_clean['Year'] = df_clean.Year.dt.year\n",
    "    df_clean['Month'] = month_new\n",
    "    df_clean['Month'] = pd.to_datetime(df_clean['Month'], format=\"%m\")\n",
    "    df_clean['Month'] = df_clean.Month.dt.month\n",
    "    df_clean['Date'] =  pd.to_datetime(df_clean[['Year', 'Month']].assign(Day=1))\n",
    "\n",
    "\n",
    "    return(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "materials_chempy",
   "language": "python",
   "name": "materials_chempy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
