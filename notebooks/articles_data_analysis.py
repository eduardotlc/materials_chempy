import pandas as pd
import numpy as np
#|%%--%%| <tS15vPWpli|P1DOSks9fT>
r"""°°°
## Reading a saved google trends csv to a dataframe

- csvpath variable should be changed
°°°"""
#|%%--%%| <P1DOSks9fT|Bvj1Gf7HNG>
csvpath = "/home/eduardotc/Downloads/multiTimeline(2).csv"
df = pd.read_csv(csvpath, header=1)
print(df)
#|%%--%%| <Bvj0Gf7HNG|vv8du6i2s2>
r"""°°°
## Sum of a google trends date column by year

- df DataFrame should be defined

- Considers the date column is a string, not a timestamp, which happens when
importing a downloaded from browser csv
°°°"""
#|%%--%%| <vv8du6i2s2|DvEkEyLo07>
df_names = df.columns.values.tolist()
col1 = df_names[0]
col2 = df_names[1]
result_df = df.groupby(df[col1].str[:4])[col2].sum().reset_index()
print(result_df)
#|%%--%%| <DvEkEyLo07|VkeLXKmmC9>
r"""°°°
## Querying a keyword all time google trends dataframe

- keyword should be defined

### Trends filters

- cat → Category to narrow results (integer)

    - Science: 174
        - Chemistry: 505
        - Biological sciences: 440
        - Computer science: 1227
        - Ecology & Environment: 442
        - Engineering & Technology: 231
        - Mathematics: 436
        - Physics: 444
        - Scientific Equipment: 445
        - Scientific Institutions: 446
    - Health: 45
        - Health conditions: 419
        - Pharmacy: 248
        - Drugs & medications: 646
        - Health Foundations & Medical Research: 252

- geo → Two letter country abreviation

    - Defaults to world
    - Example US

- timeframe

    - Date to start from
    - Defaults to last 5yrs, 'today 5-y'.
    - Everything 'all'
    - Specific dates, 'YYYY-MM-DD YYYY-MM-DD' example '2016-12-14 2017-01-25'
    - Specific datetimes, 'YYYY-MM-DDTHH YYYY-MM-DDTHH' example '2017-02-06T10 2017-02-12T07'

- gprop

    - Can be images, news, youtube or froogle (for Google Shopping results)
°°°"""
#|%%--%%| <VkeLXKmmC9|xCNVd1SWfM>
from pytrends.request import TrendReq
keyword = "plasmonic"
save_path = f"/home/eduardotc/Programação/csv/{keyword}.csv"
pytrends = TrendReq(hl='en-US', tz=360)
kw_list = [keyword]
pytrends.build_payload(kw_list, cat=0, timeframe='all', geo='', gprop='')
df = pytrends.interest_over_time()
df = df.reset_index()
df = df.drop('isPartial', axis=1)
print(df)
save_inp = str(input("Should save the dataframe to a csv? (y/n) "))
if save_inp == 'y':
    df.to_csv(path_or_buf=save_path)
#|%%--%%| <xCNVd1SWfM|jbthVjcylb>
r"""°°°
## Trends queryed dataframe treatment

Sum of the dataframe by same year time stamp from the first column

Statistics by pandas agg
°°°"""
#|%%--%%| <jbthVjcylb|9i0fsBTiZu>
df_names = df.columns.values.tolist()
col1 = df_names[0]
col2 = df_names[1]
df.groupby(df['date'].dt.year)[col2].agg(['sum', 'mean', 'max'])
#|%%--%%| <9i0fsBTiZu|H2TPNzvB7O>
r"""°°°
# Querying pubmed articles per year-month

- Variables ystart and yend defines first and last year to analyze

- keyword to search number of published articles defined from variable
°°°"""
#|%%--%%| <H2TPNzvB7O|7Ta3GtMz9H>
from metapub import PubMedFetcher
fetch = PubMedFetcher()
from time import sleep
import numpy as np
import pandas as pd
keyword = 'singlet oxygen'
save_path = f'/home/eduardotc/Programação/csv/{keyword}_pubmed.csv'
ystart = 1990
yend = 2023
df = pd.DataFrame({'date': [],
       'articles': []})
month_list = np.arange(1, 13, 1)
months_days = pd.DataFrame({'month': month_list,
                            'ends': [31, 28, 31, 30, 31, 30, 31, 31, 30, 31,
                                     30, 31]})
year_list = np.arange(ystart, yend+1, 1)
for year in year_list:
    for month in months_days['month']:
        endsin = (months_days.loc[months_days['month'] == month, 'ends'])[month-1]
        pmids = fetch.pmids_for_query(f'{keyword} '+str(year)+f'/{month}/01[MDAT] : '+str(year)+f'/{month}/{endsin}[MDAT]',retmax=100000000)
        df.loc[len(df)] = [f'{year}-{month}', len(pmids)]
        print(f"{year}-{month}: ", len(pmids))
        sleep(0.5)
pd.to_datetime(df.date, format="%Y-%m")
df
save_inp = str(input("Should save the dataframe to a csv? (y/n) "))
if save_inp == 'y':
    df.to_csv(path_or_buf=save_path)
#|%%--%%| <7PMx0fYwFN|vTVCmfDESm>
r"""°°°
# Reading and analysis of pubmed csv

- Path to the saved pubmed dataframe defined in variables

- Grouped articles by year

- Statistics generated by pandas agg
°°°"""
#|%%--%%| <vTVCmfDESm|JaqwjsWz46>
import pandas as pd
csvpath = '/home/eduardotc/Programação/csv/plasmonic_pubmed.csv'
df = pd.read_csv(csvpath, index_col=0)
df['date'] = pd.to_datetime(df.date, format="%Y-%m")
df = df.groupby(df['date'].dt.year)['articles'].agg(['sum', 'mean', 'max'])
df
#|%%--%%| <JaqwjsWz46|3W1r4iiPYs>
r"""°°°
# Matplotlib bar plotting
°°°"""
#|%%--%%| <3W1r4iiPYs|rs2LJaWmH5>
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
fig, ax = plt.subplots(figsize=(12, 4), dpi=400)
plt.xlabel('Year')
plt.ylabel('PubMed Articles')
plt.xlim(2000, 2023)
ax.set_title("Plasmonic")
ax.bar(df.index.values, df['sum'], label=df['sum'])
plt.savefig('/home/eduardotc/Programação/tstbar.png')

#|%%--%%| <rs2LJaWmH5|hxgNZIicjv>
r"""°°°
# Scopus keyword per year-month query

- Keyword defined in variables

- Years defined in variables
°°°"""
#|%%--%%| <hxgNZIicjv|WHtr1PJWVJ>
from pybliometrics.scopus import ScopusSearch
import numpy as np
import pandas as pd
keyword = 'photodynamic therapy'
save_path = f'/home/eduardotc/Programação/csv/{keyword}_scopus.csv'
months_list = ['january', 'february', 'march', 'april', 'june', 'july',
               'august', 'september', 'october', 'november', 'december']
df = pd.DataFrame({'date': [],
                   'articles': []})
ystart = 2000
yend = 2023
years_list = np.arange(ystart, yend+1, 1)
for year in years_list:
    for month in months_list:
        s = ScopusSearch(f'KEY {keyword}, PUBDATETXT({month} {year})', subscriber=False)
        print(f"{year}-{month}: ", s.get_results_size())
        df.loc[len(df)] = [f'{year}-{month}', s.get_results_size()]
        sleep(9)
df['date'] = pd.to_datetime(df.date.astype(str), format="%Y-%B")
save_inp = str(input("Should save the dataframe to a csv? (y/n) "))
if save_inp == 'y':
    df.to_csv(path_or_buf=save_path)
#|%%--%%| <WHtr1PJWVJ|37ci84yBZd>
r"""°°°
## Converting and analysing scopus dataframe

- Direct from above script, without reading csv
°°°"""
#|%%--%%| <37ci84yBZd|1ZF7R4p4dh>
import pandas as pd
df['date'] = pd.to_datetime(df.date.astype(str), format="%Y-%B")
df = df.groupby(df['date'].dt.year)['articles'].agg(['sum', 'mean', 'max'])
print(df)

#|%%--%%| <1ZF7R4p4dh|DHFTmyFwDP>
r"""°°°
# Matplotlib default configs
°°°"""
#|%%--%%| <DHFTmyFwDP|Yp3jED2upp>
import matplotlib.pyplot as plt
from cycler import cycler

plt.rcParams["pdf.use14corefonts"] = True
# trigger core fonts for PS backend
plt.rcParams["ps.useafm"] = True
# plt.rcParams['backend'] = 'Agg'
plt.rcParams.update(
    {
        "figure.dpi": 100,
        "font.size": 18,
        "figure.facecolor": "white",
        "figure.figsize": [10, 6],
        "figure.frameon": True,
        "figure.titlesize": "large",
        "figure.titleweight": "bold",
        "figure.labelsize": "medium",
        "figure.labelweight": "normal",
        "figure.edgecolor": "#000000",
    }
)

plt.rcParams.update(
    {
        "font.style": "normal",
        "font.weight": "bold",
        "font.family": "QTHelvet-Black",
        "font.sans-serif": "QTHelvet-Black",
        "font.size": 18,
    }
)

plt.rcParams.update(
    {
        "axes.grid": True,
        "axes.grid.axis": "both",
        "axes.grid.which": "major",
        "axes.labelcolor": "#172038",
        "axes.edgecolor": "#bcbcbc",
        "axes.facecolor": "#eeeeee",
        "axes.linewidth": 1.0,
    }
)

plt.rcParams.update(
    {
        "grid.alpha": 1.0,
        "grid.color": "#b2b2b2",
        "grid.linestyle": "--",
        "grid.linewidth": 0.5,
        "grid.alpha": 1.0,
    }
)

plt.rcParams.update(
    {
        "xtick.labelsize": "medium",
        "xtick.major.pad": 3.5,
        "xtick.major.size": 3.5,
        "xtick.alignment": "center",
        "xtick.color": "#000000",
        "ytick.labelsize": "x-small",
        "ytick.major.pad": 3.5,
        "ytick.major.size": 3.5,
        "ytick.alignment": "center_baseline",
        "ytick.color": "#000000",
    }
)
plt.rcParams.update(
    {
        "axes.prop_cycle": cycler(
            "color",
            [
                "#7499ff",
                "#348ABD",
                "#988ED5",
                "#777777",
                "#FBC15E",
                "#8EBA42",
                "#FFB5B8",
            ],
        )
    }
)
#|%%--%%| <Yp3jED2upp|u20TfBfLUO>
r"""°°°
# References
°°°"""
#|%%--%%| <7Ta3GtMz9H|pxyxEFYoka>
# Converting string column to datetime
df['Open'] = pd.to_datetime(df['OPEN TIME'],format= '%H:%M:%S' ).dt.time
df['Close'] = pd.to_datetime(df['CLOSE TIME'],format= '%H:%M:%S' ).dt.time

# Cleaning/removing one column or index row
df.drop('column_name', axis=1)
df.drop('row_name', axis=0)

#|%%--%%| <pxyxEFYoka|wMUzArfOEc>
r"""°°°

# TODO

- For some reason, pytrends is giving me error when not being runned from a
notebook/ipython kernel
°°°"""
#|%%--%%| <wMUzArfOEc|vFo4k1D9mn>
x = ['2015-01-01', '2015-02-01', '2015-03-01', '2015-04-01',
    '2015-06-01', '2015-07-01', '2015-08-01', '2015-09-01',
        '2015-10-01', '2015-11-01', '2015-12-01']
y = [136, 126, 122, 135, 154, 178, 187, 149, 125, 120, 120]
df = pd.DataFrame({'date': x,
                   'articles': y})
df_split = pd.DataFrame({'a': [],
                         'b': [],
                         'c': []})
for col in df.columns:
    if col == 'date':
        for values in df.date:
            parts = values.split("-")
            df_split.loc[len(df_split)] = parts
            # for time_formats in parts:
                # df = pd.DataFrame({
            # df_split = pd.DataFrame({parts})
        for cols in df_split.columns:
            print (df_split.cols)
        if len(df_split.a[0]) == 4:
            df_split.rename({'a': 'Year'}, inplace=True, axis='columns')
        print(df_split)
        # parts = df.col.split("-")
            # print(parts)
# if df['date'].values:
    # for n in df['date']:
        # parts = n.split("-")
# print(parts)
# df['date_formated'] = df['date'].dt.strftime('%Y-%m-%d')
# df['date'] = pd.to_datetime(df.date.astype(str), format="%Y-%m-%d")
# print(df)
#|%%--%%| <vFo4k1D9mn|XmeepvBio1>

# Testing Columns Variables
x = ['2015-01-01', '2015-02-01', '2015-03-01', '2015-04-01',
    '2015-06-01', '2015-07-01', '2015-08-01', '2015-09-01',
        '2015-10-01', '2015-11-01', '2015-12-01']
x2 = ['01-01-2015', '02-01-2015', '03-01-2015', '04-01-2015',
      '06-01-2015', '07-01-2015', '08-01-2015', '09-01-2015',
      '10-01-2015', '11-01-2015', '12-01-2015']
y = [136, 126, 122, 135, 154, 178, 187, 149, 125, 120, 120]

# Creating symulation of an inputted dataframe
df = pd.DataFrame({'date': x,
                   'articles': y})

# Creating empty dataframe
df_split = pd.DataFrame({'a': [],
                         'b': [],
                         'c': []})
dfn = pd.DataFrame({'Year': [],
                    'Month': []})
# Iterating for every column from inputted dataframe
for col in df.columns:

    # If input dataframe has a column named 'date'
    if col == 'date':

        # Iterating for every value from the row 'date'
        for values in df.date:

            # Spliting every 'date' value, separated by '-', in year-month-day
            # Being these 3 elements in any order
            parts = values.split("-")

            # Adding each date element to empty dataframe
            df_split.loc[len(df_split)] = parts

        # Iterating for every column in the new created every date element df
        for cols in df_split.columns:

            # If length from every element from the first row > 4 (correspond
            if len(df_split[cols][0]) == 4:
                df_split.rename({cols: 'Year'}, inplace=True, axis='columns')
        # Iterating for every column on the df again, beacause of the change
        # in one of the columns name, if the precessor loop was used to iterate
        # The others columns, an error would rise since there is no column
        # with the name that was substituted by year
        for i in df_split.columns:
            col_min = int(df_split[i].min())
            col_max = int(df_split[i].max())
            col_diff = col_max - col_min
            if 17 > col_diff > 4:
                df_split.rename({i: 'Month'}, inplace=True, axis='columns')
            elif col_diff == 0 and i != 'Year':
                df_split.drop(i, axis='columns', inplace=True)
        # print(df_split)
        df_split['Year'] = pd.to_datetime(df_split['Year'])
        df_split['Year'] = df_split['Year'].dt.strftime('%Y')

        # df_split['Month'] = pd.to_datetime(df_split['Month'])
        # df_split['Month'] = df_split['Month'].dt.strftime('%m')
            # print(np.arange(1, 11, 1))
        dfidx = (np.arange(df_split.index[0], df_split.index[-1] + 1, 1))
        # print(cols)
        # print(dfidx)
        dfstat = df_split.groupby(dfidx)['Year'].agg(['min', 'max'])
        # if len(df_split.a[0]) == 4:
            # df_split.rename({'a': 'Year'}, inplace=True, axis='columns')
        print(df_split)
        # print(dfstat)
        # parts = df.col.split("-")
            # print(parts)
# if df['date'].values:
    # for n in df['date']:
        # parts = n.split("-")
# print(parts)
# df['date_formated'] = df['date'].dt.strftime('%Y-%m-%d')
# df['date'] = pd.to_datetime(df.date.astype(str), format="%Y-%m-%d")
# print(df)


#|%%--%%| <>


# Testing Columns Variables
x = ['2015-01-01', '2015-02-01', '2015-03-01', '2015-04-01',
    '2015-06-01', '2015-07-01', '2015-08-01', '2015-09-01',
        '2015-10-01', '2015-11-01', '2015-12-01']
x2 = ['01-01-2015', '02-01-2015', '03-01-2015', '04-01-2015',
      '06-01-2015', '07-01-2015', '08-01-2015', '09-01-2015',
      '10-01-2015', '11-01-2015', '12-01-2015']
y = [136, 126, 122, 135, 154, 178, 187, 149, 125, 120, 120]
month_new = []
# Creating symulation of an inputted dataframe
df = pd.DataFrame({'date': x2,
                   'articles': y})

# Creating empty dataframe
df_split = pd.DataFrame({'a': [],
                         'b': [],
                         'c': []})
dfn = pd.DataFrame({'Year': [],
                    'Month': [],
                    'Date': []})
# Iterating for every column from inputted dataframe
for col in df.columns:

    # If input dataframe has a column named 'date'
    if col == 'date':

        # Iterating for every value from the row 'date'
        for values in df.date:

            # Adding each date element to empty dataframe
            df_split.loc[len(df_split)] = values.split("-")

        # Iterating for every column in the new created every date element df
        for cols in df_split.columns:

            # If length from every element from the first row > 4 (correspond
            if len(df_split[cols][0]) == 4:
                dfn['Year'] = df_split[cols]
            col_min = int(df_split[cols].min())
            col_max = int(df_split[cols].max())
            col_diff = col_max - col_min
            if 17 > col_diff > 4:
                dfn['Month'] = df_split[cols]

for number in dfn.Month:
    month_new.append(int(str(number).rstrip('0')))

dfn['Year'] = pd.to_datetime(dfn['Year'])
dfn['Year'] = dfn.Year.dt.year
dfn['Month'] = month_new
dfn['Month'] = pd.to_datetime(dfn['Month'], format="%m")
dfn['Month'] = dfn.Month.dt.month
dfn['Date'] =  pd.to_datetime(dfn[['Year', 'Month']].assign(Day=1))
print(dfn)
#|%%--%%| <|4Q8GLd63nK>


# Testing Columns Variables
x = ['2015-01-01', '2015-02-01', '2015-03-01', '2015-04-01',
    '2015-06-01', '2015-07-01', '2015-08-01', '2015-09-01',
        '2015-10-01', '2015-11-01', '2015-12-01']
x2 = ['01-01-2015', '02-01-2015', '03-01-2015', '04-01-2015',
      '06-01-2015', '07-01-2015', '08-01-2015', '09-01-2015',
      '10-01-2015', '11-01-2015', '12-01-2015']
y = [136, 126, 122, 135, 154, 178, 187, 149, 125, 120, 120]
month_new = []

# Creating symulation of an inputted dataframe
# df = pd.DataFrame({'date': x2,
                   # 'articles': y})

df = pd.read_csv('/home/eduardotc/Upconversion_scopus.csv', index_col=0)

# Creating empty dataframe in case readed csv 'date' column is shorter than 7
if (len(df.date[0])) < 7:
    df_split = pd.DataFrame({'a': [],
                             'b': []})

# Creating empty dataframe in case readed csv 'date' column is longer than 7
    df_split = pd.DataFrame({'a': [],
                             'b': [],
                             'c': []})

dfn = pd.DataFrame({'Year': [],
                    'Month': [],
                    'Date': [],
                    'Articles': []})

# Iterating for every column from inputted dataframe
for col in df.columns:

    # If input dataframe has a column named 'articles'
    if col == 'articles' or col == 'Articles':
        dfn['Articles'] = df['articles']

    # If input dataframe has a column named 'date'
    if col == 'date' or col == 'Date':

        # Iterating for every value from the row 'date'
        for values in df.date:

            # Adding each date element to empty dataframe
            df_split.loc[len(df_split)] = values.split("-")

        # Iterating for every column in the new created every date element df
        for cols in df_split.columns:

            # If length from every element from the first row > 4 (correspond
            # (High chances of being a year column)
            if len(df_split[cols][0]) == 4:
                dfn['Year'] = df_split[cols]

            # Getting total column values range (max - min)
            col_min = int(df_split[cols].min())
            col_max = int(df_split[cols].max())
            col_diff = col_max - col_min

            # Loop if the column range is between 17 and 4 (high chances of
            # being a month column
            if 17 > col_diff > 4:
                dfn['Month'] = df_split[cols]

# Removing month column trailing zeroes
for number in dfn.Month:
    month_new.append(int(str(number).rstrip('0')))

# Converting year month and date columns to pandas datetime
dfn['Year'] = pd.to_datetime(dfn['Year'])
dfn['Year'] = dfn.Year.dt.year
dfn['Month'] = month_new
dfn['Month'] = pd.to_datetime(dfn['Month'], format="%m")
dfn['Month'] = dfn.Month.dt.month
dfn['Date'] =  pd.to_datetime(dfn[['Year', 'Month']].assign(Day=1))


print(dfn)
